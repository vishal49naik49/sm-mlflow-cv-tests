{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4057541d-91f0-4697-8c21-91168b10c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0.post104)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.2a0+ab7b3e6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75038395-4dcb-4518-9f37-4106c6d31580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2a7f8e-4070-4c76-8dbe-13313e5acc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4314cfef-c750-4f1c-a082-5bd8b03e15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class LegoDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e777b3ea-39f3-4d29-b28c-3ef7464e7f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class LegoCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LegoCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00fbf076-81a1-4c93-88c6-4dfd541813c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_hash(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        return hashlib.md5(f.read()).hexdigest()\n",
    "\n",
    "def load_data(good_dir, defective_dir):\n",
    "    good_images = [os.path.join(good_dir, f) for f in os.listdir(good_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    defective_images = [os.path.join(defective_dir, f) for f in os.listdir(defective_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Remove duplicates\n",
    "    hash_dict = {}\n",
    "    unique_good_images = []\n",
    "    unique_defective_images = []\n",
    "    \n",
    "    unique_images = good_images + defective_images #unique_defective_images\n",
    "    unique_labels = [0] * len(good_images) + [1] * len(defective_images) #unique_defective_images)\n",
    "    \n",
    "    print(f\"Total good images: {len(good_images)}\")\n",
    "    print(f\"Unique good images: {len(unique_good_images)}\")\n",
    "    print(f\"Total defective images: {len(defective_images)}\")\n",
    "    print(f\"Unique defective images: {len(unique_defective_images)}\")\n",
    "    print(f\"Total images: {len(good_images) + len(defective_images)}\")\n",
    "    print(f\"Total unique images: {len(unique_images)}\")\n",
    "    \n",
    "    return train_test_split(unique_images, unique_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f3eaa77-0860-4e53-be81-61073fabc455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total good images: 10\n",
      "Unique good images: 0\n",
      "Total defective images: 10\n",
      "Unique defective images: 0\n",
      "Total images: 20\n",
      "Total unique images: 20\n",
      "\n",
      "Training set:\n",
      "Total images: 16\n",
      "Good images: 8\n",
      "Defective images: 8\n",
      "\n",
      "Test set:\n",
      "Total images: 4\n",
      "Good images: 2\n",
      "Defective images: 2\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "# Set up data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load and prepare the data\n",
    "good_dir = 'Images/Good'\n",
    "defective_dir = 'Images/Defective'\n",
    "train_images, test_images, train_labels, test_labels = load_data(good_dir, defective_dir)\n",
    "\n",
    "# Print breakdown of train and test sets\n",
    "print(\"\\nTraining set:\")\n",
    "print(f\"Total images: {len(train_images)}\")\n",
    "print(f\"Good images: {sum(1 for label in train_labels if label == 0)}\")\n",
    "print(f\"Defective images: {sum(1 for label in train_labels if label == 1)}\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(f\"Total images: {len(test_images)}\")\n",
    "print(f\"Good images: {sum(1 for label in test_labels if label == 0)}\")\n",
    "print(f\"Defective images: {sum(1 for label in test_labels if label == 1)}\")\n",
    "\n",
    "train_dataset = LegoDataset(train_images, train_labels, transform=transform)\n",
    "test_dataset = LegoDataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d4af7b8-6371-4075-8ac9-829a9c1528e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.6962, Test Accuracy: 50.00%\n",
      "Epoch [2/15], Loss: 0.6856, Test Accuracy: 50.00%\n",
      "Epoch [3/15], Loss: 0.6759, Test Accuracy: 50.00%\n",
      "Epoch [4/15], Loss: 0.6368, Test Accuracy: 50.00%\n",
      "Epoch [5/15], Loss: 0.6486, Test Accuracy: 50.00%\n",
      "Epoch [6/15], Loss: 0.6639, Test Accuracy: 50.00%\n",
      "Epoch [7/15], Loss: 0.5936, Test Accuracy: 100.00%\n",
      "Epoch [8/15], Loss: 0.5929, Test Accuracy: 75.00%\n",
      "Epoch [9/15], Loss: 0.3908, Test Accuracy: 75.00%\n",
      "Epoch [10/15], Loss: 0.4122, Test Accuracy: 75.00%\n",
      "Epoch [11/15], Loss: 0.2654, Test Accuracy: 100.00%\n",
      "Epoch [12/15], Loss: 0.1984, Test Accuracy: 100.00%\n",
      "Epoch [13/15], Loss: 0.1133, Test Accuracy: 100.00%\n",
      "Epoch [14/15], Loss: 0.1834, Test Accuracy: 100.00%\n",
      "Epoch [15/15], Loss: 0.1762, Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LegoCNN().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.squeeze() == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a72d373-153a-4d34-a4c4-cdd04448648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return transform(image).unsqueeze(0)  \n",
    "\n",
    "def predict_image(image_path, model):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        image = preprocess_image(image_path).to(device)\n",
    "        output = model(image)\n",
    "        probability = torch.sigmoid(output).item()\n",
    "        prediction = \"Good\" if probability < 0.5 else \"Defective\"\n",
    "        # normalized_prob = probability*100\n",
    "        # return_prob =  100-normalized_prob\n",
    "        return prediction, probability, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1c292df-eb7f-497f-8170-2edad427117a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Images/Good/image_0d06e4a3-c6a6-4130-9e6f-363e44831dcc.jpg\n",
      "Prediction: Good\n",
      "Output: tensor([[-5.7247]])\n",
      "Probability of being defective: 0.00\n",
      "---\n",
      "Image: Images/Good/image_23120a2b-0ead-408a-824a-bc909e9de2b9.jpg\n",
      "Prediction: Good\n",
      "Output: tensor([[-4.3019]])\n",
      "Probability of being defective: 0.01\n",
      "---\n",
      "Image: Images/Defective/0-change lego block to purple.png\n",
      "Prediction: Defective\n",
      "Output: tensor([[5.7365]])\n",
      "Probability of being defective: 1.00\n",
      "---\n",
      "Image: Images/Defective/1-change lego block to light green.png\n",
      "Prediction: Defective\n",
      "Output: tensor([[2.2022]])\n",
      "Probability of being defective: 0.90\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "test_images = [  \n",
    "    'Images/Good/image_0d06e4a3-c6a6-4130-9e6f-363e44831dcc.jpg',    \n",
    "    'Images/Good/image_23120a2b-0ead-408a-824a-bc909e9de2b9.jpg',\n",
    "    'Images/Defective/0-change lego block to purple.png',\n",
    "    'Images/Defective/1-change lego block to light green.png'\n",
    "]\n",
    "\n",
    "for img_path in test_images:\n",
    "    prediction, probability, output = predict_image(img_path, model)\n",
    "    print(f\"Image: {img_path}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"Output: {output}\")\n",
    "    print(f\"Probability of being defective: {probability:.2f}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8245d03-382e-4f57-8e08-97bee31b1167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 03:51:53.907765: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4c30cab-b2ea-4587-ac73-2e3357a4a907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/19 03:52:43 INFO mlflow.tracking.fluent: Experiment with name 'Lego-Quality-Classification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://sm-mlflow-vsnak-iad-316413003582/34', creation_time=1734580363554, experiment_id='34', last_update_time=1734580363554, lifecycle_stage='active', name='Lego-Quality-Classification', tags={}>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize MLflow\n",
    "\n",
    "arn = 'arn:aws:sagemaker:us-east-1:316413003582:mlflow-tracking-server/sample-mlflow-tracking'\n",
    "\n",
    "mlflow.set_tracking_uri(arn)\n",
    "mlflow.set_experiment(\"Lego-Quality-Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de4d13fc-36bb-4cf9-8549-bf1d0b0b3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, device):\n",
    "    with mlflow.start_run():\n",
    "        # Log model parameters\n",
    "        mlflow.log_param(\"learning_rate\", optimizer.param_groups[0]['lr'])\n",
    "        mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "        mlflow.log_param(\"batch_size\", train_loader.batch_size)\n",
    "        mlflow.log_param(\"optimizer\", type(optimizer).__name__)\n",
    "\n",
    "        best_accuracy = 0.0\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            # Calculate average loss for the epoch\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            test_loss = 0.0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    test_loss += criterion(outputs, labels.float().unsqueeze(1)).item()\n",
    "                    predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted.squeeze() == labels).sum().item()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            test_loss = test_loss / len(test_loader)\n",
    "\n",
    "            # Log metrics to MLflow\n",
    "            mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
    "            mlflow.log_metric(\"test_loss\", test_loss, step=epoch)\n",
    "            mlflow.log_metric(\"test_accuracy\", accuracy, step=epoch)\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "            # Save best model\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                # Save model to MLflow\n",
    "                mlflow.pytorch.log_model(model, \"best_model\")\n",
    "\n",
    "        # Log the final model\n",
    "        mlflow.pytorch.log_model(model, \"final_model\")\n",
    "\n",
    "        # Log additional artifacts if needed\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            # Save model architecture diagram or other artifacts\n",
    "            model_summary_path = os.path.join(temp_dir, \"model_summary.txt\")\n",
    "            with open(model_summary_path, \"w\") as f:\n",
    "                f.write(str(model))\n",
    "            mlflow.log_artifact(model_summary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ea3f571-57af-42a7-abbc-493110edfd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.6912, Test Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/19 03:53:28 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.15.2a0+ab7b3e6) contains a local version label (+ab7b3e6). MLflow logged a pip requirement for this package as 'torchvision==0.15.2a0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], Loss: 0.6905, Test Accuracy: 50.00%\n",
      "Epoch [3/15], Loss: 0.6782, Test Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/19 03:53:39 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.15.2a0+ab7b3e6) contains a local version label (+ab7b3e6). MLflow logged a pip requirement for this package as 'torchvision==0.15.2a0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], Loss: 0.6575, Test Accuracy: 100.00%\n",
      "Epoch [5/15], Loss: 0.6348, Test Accuracy: 100.00%\n",
      "Epoch [6/15], Loss: 0.5604, Test Accuracy: 100.00%\n",
      "Epoch [7/15], Loss: 0.4991, Test Accuracy: 100.00%\n",
      "Epoch [8/15], Loss: 0.4241, Test Accuracy: 100.00%\n",
      "Epoch [9/15], Loss: 0.3245, Test Accuracy: 75.00%\n",
      "Epoch [10/15], Loss: 0.2429, Test Accuracy: 100.00%\n",
      "Epoch [11/15], Loss: 0.1758, Test Accuracy: 75.00%\n",
      "Epoch [12/15], Loss: 0.1626, Test Accuracy: 100.00%\n",
      "Epoch [13/15], Loss: 0.1510, Test Accuracy: 100.00%\n",
      "Epoch [14/15], Loss: 0.0371, Test Accuracy: 100.00%\n",
      "Epoch [15/15], Loss: 0.2122, Test Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/19 03:53:54 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.15.2a0+ab7b3e6) contains a local version label (+ab7b3e6). MLflow logged a pip requirement for this package as 'torchvision==0.15.2a0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    }
   ],
   "source": [
    "model = LegoCNN().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model with MLflow tracking\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=15, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bad9ab45-513f-4ea0-9933-e2e021f901ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_mlflow(image_path, run_id=None):\n",
    "    with mlflow.start_run(run_name=\"prediction\"):\n",
    "        if run_id:\n",
    "            # Load the model from MLflow\n",
    "            loaded_model = mlflow.pytorch.load_model(f\"runs:/{run_id}/best_model\")\n",
    "            loaded_model.to(device)\n",
    "            prediction, probability, output = predict_image(image_path, loaded_model)\n",
    "        else:\n",
    "            prediction, probability, output = predict_image(image_path, model)\n",
    "        \n",
    "        # Log prediction results\n",
    "        mlflow.log_param(\"image_path\", image_path)\n",
    "        mlflow.log_metric(\"prediction_probability\", probability)\n",
    "        mlflow.log_param(\"predicted_class\", prediction)\n",
    "        \n",
    "        # Optional: Log the input image as an artifact\n",
    "        mlflow.log_artifact(image_path)\n",
    "        \n",
    "        # Optional: Create and log a prediction results summary\n",
    "        results_path = \"prediction_results.txt\"\n",
    "        with open(results_path, \"w\") as f:\n",
    "            f.write(f\"Image: {image_path}\\n\")\n",
    "            f.write(f\"Prediction: {prediction}\\n\")\n",
    "            f.write(f\"Probability: {probability}\\n\")\n",
    "            f.write(f\"Raw Output: {output}\\n\")\n",
    "        mlflow.log_artifact(results_path)\n",
    "        \n",
    "        return prediction, probability, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0baee57e-f259-4801-95a3-0814e5f5cb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Images/Good/image_0d06e4a3-c6a6-4130-9e6f-363e44831dcc.jpg\n",
      "Prediction: Good\n",
      "Output: tensor([[-4.7222]])\n",
      "Probability of being defective: 0.01\n",
      "---\n",
      "Image: Images/Good/image_23120a2b-0ead-408a-824a-bc909e9de2b9.jpg\n",
      "Prediction: Good\n",
      "Output: tensor([[-4.7580]])\n",
      "Probability of being defective: 0.01\n",
      "---\n",
      "Image: Images/Defective/0-change lego block to purple.png\n",
      "Prediction: Defective\n",
      "Output: tensor([[11.0956]])\n",
      "Probability of being defective: 1.00\n",
      "---\n",
      "Image: Images/Defective/1-change lego block to light green.png\n",
      "Prediction: Defective\n",
      "Output: tensor([[3.1716]])\n",
      "Probability of being defective: 0.96\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Test predictions\n",
    "for img_path in test_images:\n",
    "    prediction, probability, output = predict_with_mlflow(img_path)\n",
    "    print(f\"Image: {img_path}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"Output: {output}\")\n",
    "    print(f\"Probability of being defective: {probability:.2f}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0eb33e-c3ce-45db-92a5-d7064de8de53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
